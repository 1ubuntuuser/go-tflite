{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting handwriting number with mnist\n",
    "\n",
    "The model of mnist is generated using numpy/keras on Python.\n",
    "\n",
    "```python\n",
    "from tensorflow.contrib.keras.api.keras.datasets import mnist\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.contrib.keras.api.keras.optimizers import Adam\n",
    "from tensorflow.contrib.keras.api.keras.utils import to_categorical\n",
    "import tensorflow.contrib.lite as lite\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train  = x_train.reshape(60000, 784)\n",
    "x_test   = x_test.reshape(10000, 784)\n",
    "x_train  = x_train.astype('float32')\n",
    "x_test   = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test  /= 255\n",
    "y_train  = to_categorical(y_train, 10)\n",
    "y_test   = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save('mnist_model.h5')\n",
    "\n",
    "converter = lite.TFLiteConverter.from_keras_model_file('mnist_model.h5')\n",
    "tflite_model = converter.convert()\n",
    "open('mnist_model.tflite', 'wb').write(tflite_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first, import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"image\"\n",
    "    _ \"image/png\"\n",
    "    \"log\"\n",
    "    \"os\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And go-tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"github.com/mattn/go-tflite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tflite model file that is generated by Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model := tflite.NewModelFromFile(\"mnist_model.tflite\")\n",
    "if model == nil {\n",
    "    log.Fatal(\"cannot load model\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now you can create interpreter of TensorFlow Lite. The second argument is InterpreterOptions. If you want to specify thread number of the interpreter, modify options that created by NewInterpreterOptions.\n",
    " ```go\n",
    "options := tflite.NewInterpreterOptions()\n",
    "options.SetNumThread(4)\n",
    "defer options.Delete()\n",
    "\n",
    "interpreter := tflite.NewInterpreter(model, options)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter := tflite.NewInterpreter(model, nil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate tensors according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if status := interpreter.AllocateTensors(); status != tflite.OK {\n",
    "    log.Fatal(\"cannot allocate tensors\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load an image file\n",
    "\n",
    "![](3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, err := os.Open(\"3.png\")\n",
    "if err != nil {\n",
    "    log.Fatal(err)\n",
    "}\n",
    "img, _, err := image.Decode(f)\n",
    "if err != nil {\n",
    "    log.Fatal(err)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist images are cropped as 28x28 images. So the input image must be resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"github.com/nfnt/resize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized := resize.Resize(28, 28, img, resize.NearestNeighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can update this slice directly. It can use built-in function copy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in := interpreter.GetInputTensor(0).Float32s()\n",
    "for y := 0; y < 28; y++ {\n",
    "    for x := 0; x < 28; x++ {\n",
    "        r, g, b, _ := resized.At(x, y).RGBA()\n",
    "        in[y*28+x] = (float32(b) + float32(g) + float32(r)) / 3.0 / 65535.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, call `Invoke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if status := interpreter.Invoke(); status != tflite.OK {\n",
    "    log.Fatal(\"invoke failed\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can access output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out := interpreter.GetOutputTensor(0).Float32s()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`out` is slice of float32 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.87487e-13 5.2886115e-08 1.007325e-06 0.9999981 3.8918652e-15 2.0818582e-08 2.8191183e-16 5.3700126e-07 2.8028694e-07 7.383084e-11]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wanted number is encodeded as offset that Python encoded this number as 1 hot. Then, add function to get index of item which is largest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func top(a []float32) int {\n",
    "    t := 0\n",
    "    m := float32(0)\n",
    "    for i, e := range a {\n",
    "        if i == 0 || e > m {\n",
    "            m = e\n",
    "            t = i\n",
    "        }\n",
    "    }\n",
    "    return t\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted number is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number written on the image is: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38 <nil>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmt.Println(\"The number written on the image is:\", top(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "devel +04f1b65cc6 Wed Mar 13 15:11:37 2019 +0000"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
